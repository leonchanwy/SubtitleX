import streamlit as st
import openai
from pathlib import Path
import tempfile
import os

def set_openai_api_key(api_key):
    openai.api_key = api_key

def transcribe_audio(audio_file, model, language, prompt, response_format, temperature, timestamp_granularities=None):
    params = {
        "model": model,
        "file": audio_file,
        "language": language if language else None,
        "prompt": prompt if prompt else None,
        "response_format": response_format,
        "temperature": temperature
    }
    if timestamp_granularities:
        params["timestamp_granularities"] = timestamp_granularities
    
    transcript = openai.audio.transcriptions.create(**params)
    return transcript.text if response_format == 'json' else transcript

def translate_audio(audio_file, model, prompt, response_format, temperature):
    translation = openai.audio.translations.create(
        model=model,
        file=audio_file,
        prompt=prompt if prompt else None,
        response_format=response_format,
        temperature=temperature
    )
    return translation.text if response_format == 'json' else translation

def text_to_speech(text, model, voice, response_format, speed):
    response = openai.audio.speech.create(
        model=model,
        voice=voice,
        input=text,
        response_format=response_format,
        speed=speed
    )
    return response.content

def whisper_api_tool():
    st.title("ğŸ‡¯ğŸ‡µ Whisper API Tool")
    api_key = st.text_input("è¼¸å…¥æ‚¨çš„ OpenAI API Key", value=st.session_state.api_key, type="password")
    if api_key != st.session_state.api_key:
        st.session_state.api_key = api_key
        save_api_key(api_key)
        st.success("API Key å·²ä¿å­˜")

    tab1, tab2, tab3 = st.tabs(["éŸ³é »è½‰éŒ„", "éŸ³é »ç¿»è­¯", "æ–‡å­—è½‰èªéŸ³"])

    # å®šç¾©èªè¨€åˆ—è¡¨ï¼Œå°‡æŒ‡å®šèªè¨€æ”¾åœ¨å‰é¢
    languages = [
        ("zh", "ä¸­æ–‡"),
        ("en", "è‹±æ–‡"),
        ("ms", "é¦¬ä¾†æ–‡"),
        ("ja", "æ—¥æ–‡"),
        ("de", "å¾·æ–‡"),
        ("af", "å—éè·è˜­èª"),
        ("ar", "é˜¿æ‹‰ä¼¯èª"),
        ("hy", "äºç¾å°¼äºèª"),
        ("az", "é˜¿å¡æ‹œç–†èª"),
        ("be", "ç™½ä¿„ç¾…æ–¯èª"),
        ("bs", "æ³¢æ–¯å°¼äºèª"),
        ("bg", "ä¿åŠ åˆ©äºèª"),
        ("ca", "åŠ æ³°ç¾…å°¼äºèª"),
        ("hr", "å…‹ç¾…åœ°äºèª"),
        ("cs", "æ·å…‹èª"),
        ("da", "ä¸¹éº¥èª"),
        ("nl", "è·è˜­èª"),
        ("et", "æ„›æ²™å°¼äºèª"),
        ("fi", "èŠ¬è˜­èª"),
        ("fr", "æ³•èª"),
        ("gl", "åŠ åˆ©è¥¿äºèª"),
        ("el", "å¸Œè‡˜èª"),
        ("he", "å¸Œä¼¯ä¾†èª"),
        ("hi", "å°åœ°èª"),
        ("hu", "åŒˆç‰™åˆ©èª"),
        ("is", "å†°å³¶èª"),
        ("id", "å°å°¼èª"),
        ("it", "ç¾©å¤§åˆ©èª"),
        ("kk", "å“ˆè–©å…‹èª"),
        ("ko", "éŸ“èª"),
        ("lv", "æ‹‰è„«ç¶­äºèª"),
        ("lt", "ç«‹é™¶å®›èª"),
        ("mk", "é¦¬å…¶é “èª"),
        ("mi", "æ¯›åˆ©èª"),
        ("mr", "é¦¬æ‹‰åœ°èª"),
        ("ne", "å°¼æ³Šçˆ¾èª"),
        ("no", "æŒªå¨èª"),
        ("fa", "æ³¢æ–¯èª"),
        ("pl", "æ³¢è˜­èª"),
        ("pt", "è‘¡è„ç‰™èª"),
        ("ro", "ç¾…é¦¬å°¼äºèª"),
        ("ru", "ä¿„èª"),
        ("sr", "å¡çˆ¾ç¶­äºèª"),
        ("sk", "æ–¯æ´›ä¼å…‹èª"),
        ("sl", "æ–¯æ´›ç¶­å°¼äºèª"),
        ("es", "è¥¿ç­ç‰™èª"),
        ("sw", "æ–¯ç“¦å¸Œé‡Œèª"),
        ("sv", "ç‘å…¸èª"),
        ("tl", "ä»–åŠ ç¥¿èª"),
        ("ta", "æ³°ç±³çˆ¾èª"),
        ("th", "æ³°èª"),
        ("tr", "åœŸè€³å…¶èª"),
        ("uk", "çƒå…‹è˜­èª"),
        ("ur", "çƒçˆ¾éƒ½èª"),
        ("vi", "è¶Šå—èª"),
        ("cy", "å¨çˆ¾å£«èª")
    ]

    with tab1:
        st.header("éŸ³é »è½‰éŒ„")
        uploaded_file = st.file_uploader("é¸æ“‡éŸ³é »æ–‡ä»¶", type=["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"], key="transcribe_file_uploader")
        model = st.selectbox("æ¨¡å‹", ["whisper-1"], key="transcribe_model")
        language = st.selectbox("èªè¨€", languages, format_func=lambda x: f"{x[1]} ({x[0]})", key="transcribe_language")
        prompt = st.text_area("æç¤ºè© (å¯é¸)", key="transcribe_prompt")
        response_format = st.selectbox("éŸ¿æ‡‰æ ¼å¼", ["json", "text", "srt", "verbose_json", "vtt"], key="transcribe_response_format")
        temperature = st.slider("æº«åº¦", 0.0, 1.0, 0.0, 0.1, key="transcribe_temperature")
        
        # åªæœ‰ç•¶ response_format ç‚º verbose_json æ™‚æ‰é¡¯ç¤º timestamp_granularities é¸é …
        timestamp_granularities = None
        if response_format == "verbose_json":
            timestamp_options = st.multiselect(
                "æ™‚é–“æˆ³ç²¾åº¦",
                ["word", "segment"],
                default=["segment"],
                help="é¸æ“‡æ™‚é–“æˆ³çš„ç²¾åº¦ã€‚æ³¨æ„ï¼šç”Ÿæˆè©ç´šæ™‚é–“æˆ³æœƒå¢åŠ å»¶é²ã€‚",
                key="transcribe_timestamp_granularities"
            )
            if timestamp_options:
                timestamp_granularities = timestamp_options
        
        if uploaded_file is not None and st.button("è½‰éŒ„", key="transcribe_button"):
            with st.spinner("æ­£åœ¨è½‰éŒ„..."):
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                with open(tmp_file_path, "rb") as audio_file:
                    transcript = transcribe_audio(audio_file, model, language[0], prompt, response_format, temperature, timestamp_granularities)
                
                os.unlink(tmp_file_path)
                
                st.text_area("è½‰éŒ„çµæœ", transcript, height=250, key="transcribe_result")


    with tab2:
        st.header("éŸ³é »ç¿»è­¯")
        uploaded_file = st.file_uploader("é¸æ“‡è¦ç¿»è­¯çš„éŸ³é »æ–‡ä»¶", type=["mp3", "mp4", "mpeg", "mpga", "m4a", "wav", "webm"], key="translate_file_uploader")
        model = st.selectbox("æ¨¡å‹", ["whisper-1"], key="translate_model")
        prompt = st.text_area("æç¤ºè© (å¯é¸)", key="translate_prompt")
        response_format = st.selectbox("éŸ¿æ‡‰æ ¼å¼", ["json", "text", "srt", "verbose_json", "vtt"], key="translate_response_format")
        temperature = st.slider("æº«åº¦", 0.0, 1.0, 0.0, 0.1, key="translate_temperature")
        
        if uploaded_file is not None and st.button("ç¿»è­¯", key="translate_button"):
            with st.spinner("æ­£åœ¨ç¿»è­¯..."):
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name
                
                with open(tmp_file_path, "rb") as audio_file:
                    translation = translate_audio(audio_file, model, prompt, response_format, temperature)
                
                os.unlink(tmp_file_path)
                
                st.text_area("ç¿»è­¯çµæœ", translation, height=250, key="translate_result")

    with tab3:
        st.header("æ–‡å­—è½‰èªéŸ³")
        text_input = st.text_area("è¼¸å…¥è¦è½‰æ›ç‚ºèªéŸ³çš„æ–‡å­—", height=150, key="tts_input")
        model = st.selectbox("æ¨¡å‹", ["tts-1", "tts-1-hd"], key="tts_model")
        voice = st.selectbox("é¸æ“‡è²éŸ³", ["alloy", "echo", "fable", "onyx", "nova", "shimmer"], key="tts_voice")
        response_format = st.selectbox("éŸ³é »æ ¼å¼", ["mp3", "opus", "aac", "flac"], key="tts_response_format")
        speed = st.slider("é€Ÿåº¦", 0.25, 4.0, 1.0, 0.25, key="tts_speed")
        
        if text_input and st.button("ç”ŸæˆèªéŸ³", key="tts_button"):
            with st.spinner("æ­£åœ¨ç”ŸæˆéŸ³é »..."):
                audio_content = text_to_speech(text_input, model, voice, response_format, speed)
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=f".{response_format}") as tmp_audio_file:
                    tmp_audio_file.write(audio_content)
                    tmp_audio_file_path = tmp_audio_file.name
                
                st.audio(tmp_audio_file_path, format=f"audio/{response_format}")
                
                os.unlink(tmp_audio_file_path)